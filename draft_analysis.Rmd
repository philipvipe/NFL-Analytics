---
title: 'NFL Draft Analysis'
author: "Philip Ipe"
date: "5/8/2020"
output: html_document
knit: (function(input_file, encoding) {
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), 'index.html'))})
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(tidyverse)
library(rvest)
library(gridExtra)
library(caret)
library(knitr)
setwd("/Users/PhilipIpe/Documents/Data Science/Projects/NFL Draft Analytics/")
```

# Part 1: Data Collection

We will scrape historical draft data from Pro-Football Reference from years 1970 till 2016. We chose to stop at 2016 since rookies usually sign 4 year deals, so the four year mark is typically when each team will finish evaulating each player they drafted, and make a decision on whether or not to resign the player. So, the jury is still out on players drafted after 2016.  We will filter out any selections after round 7, as since 1994, the NFL draft has only consisted of 7 rounds. 

The result will be stored in the dataframe *master_df* with entities for each player.

Note: We will also do some process in this step as well, but we will go into more detail on that when we repeat the processing steps in another dataframe later in the walkthrough.
    
```{r scrape_master}

master_df <- data.frame()
for (year in 1970:2016){
  
  draft_url <- paste("https://www.pro-football-reference.com/years/", year, "/draft.htm", sep="")
  draft_html <- read_html(draft_url)

  df <- draft_html %>%
    html_node("table") %>%
    html_table()

  names(df) <- as.character(unlist(df[1,]))
  df <- df[-1,]
  
  # get rid of the columns we dont care about
  df <- df[,1:13]
  
  df$Rnd <- as.integer(df$Rnd)
  df$Age <- as.integer(df$Age)
  df$CarAV <- as.integer(df$CarAV)
  df$DrAV <- as.integer(df$DrAV)
  df$G <- as.integer(df$G)
  
  # filter out certain rounds
  df <- df %>%
    filter(Rnd < 8)
  
  # get rid of blank rows
  df <-df[!(df$Player=="Player"),]
  
  # add year drafted to each observation
  df <- df %>%
    mutate(year = year)
    
  master_df <- rbind(master_df, df)
}
```

We will also scrape the data from the 2020 draft in the same way for use in our machine learning problem and save it to our *df_2020* variable. 

```{r scrape_2020}

draft_url <- "https://www.pro-football-reference.com/years/2020/draft.htm"
draft_html <- read_html(draft_url)

df_2020 <- draft_html %>%
  html_node("table") %>%
  html_table()

names(df_2020) <- as.character(unlist(df_2020[1,]))
df_2020 <- df_2020[-1,]
```

We will also scrape the 2017-2019 NFL draft data into a seperate dataframe *test_df*, which will be used to test our machine learning model that we will develop later in the tutorial.

```{r scrape_test}
test_df <- data.frame()
for (year in 2017:2019){
  
  draft_url <- paste("https://www.pro-football-reference.com/years/", year, "/draft.htm", sep="")
  draft_html <- read_html(draft_url)

  df <- draft_html %>%
    html_node("table") %>%
    html_table()

  names(df) <- as.character(unlist(df[1,]))
  df <- df[-1,]
  
  # get rid of the columns we dont care about
  df <- df[,1:6]
  
  # add year drafted to each observation
  df <- df %>%
    mutate(year = year)

  test_df <- rbind(test_df, df)
}

```

Next we will scrape the AP Offensive Rookie of the Year Winners from the same website, again for our machine learning problem.

```{r scrape_ROTY}

roty_url <- "https://www.pro-football-reference.com/awards/ap-offensive-rookie-of-the-year-award.htm"
draft_html <- read_html(roty_url)

roty_df <- draft_html %>%
  html_node("table") %>%
  html_table()
```

# Part 2: Data Processing and Preparation

Load the NFL draft history data from *master_df*, containing the draft data from rounds 1-7 from the 1970-2016 NFL draft. Remove all of the missing data entries, and convert the necessary columns to integers. 

    
```{r process_master}

master_df <- master_df[complete.cases(master_df[,12:13]),]
master_df$Rnd <- as.factor(master_df$Rnd)
master_df$Tm <- as.factor(master_df$Tm)
master_df$Pos <- as.factor(master_df$Pos)

master_df$Age <- as.integer(master_df$Age)
master_df$CarAV <- as.integer(master_df$CarAV)
master_df$DrAV <- as.integer(master_df$DrAV)
master_df$G <- as.integer(master_df$G)
master_df$Pick <- as.integer(master_df$Pick)

kable(head(master_df))
```

Our *master_df* dataframe now has entities for each player with the following variables:

    Rnd : Round in which the player was selected
    
    Pick: Overall selection in draft
    
    Tm  : Team
    
    Player: Player name
    
    Pos : Position
    
    Age
    
    To: Last year in the league
    
    AP1: First team All-Pro selections
    
    PB: Pro Bowl selections
    
    St: Number of years as primary starter for his team at his position
    
    CarAv: Weighted Career Approximate Value
    
                  = 100% of AV of his best season + 95% of AV of his next best season + 90% of AV of his third-best season + ...
                  
    DrAV: Average value accumulated for the team that drafted this player
    
    G : Games Played
    
    year: Year drafted

Now let's process our 2020 Draft data. First, we will get rid of columns we don't care about, then remove blank rows, add year drafted to each observation, and convert the necessary columns to integers, all like we did for the historical draft dataset. We will also filter this dataframe to only include quarterbacks, wide receivers, and running backs.

```{r process2020}
# get rid of the columns we dont care about
df_2020 <- df_2020[,1:6]

# filter out certain rounds
df_2020 <- df_2020 %>%
  filter(Rnd < 8)
  
# get rid of blank rows
df_2020 <-df_2020[!(df_2020$Player=="Player"),]
  
# add year drafted to each observation, and filter out the defensive players.
df_2020 <- df_2020 %>%
  mutate(year = year) %>%
  filter(Pos == "QB" | Pos == "WR" | Pos == "RB")

df_2020[is.na(df_2020)] <- 22

df_2020$Pick <- as.integer(df_2020$Pick)
df_2020$Age <- as.integer(df_2020$Age)
df_2020$Tm <- as.factor(df_2020$Tm)
df_2020$Pos <- as.factor(df_2020$Pos)

kable(head(df_2020))
```

So, now our *df_2020* dataframe contains only the offensive skill position players that were drafted in 2020 as entities. The variables of this dataframe are **Rnd**, **Pick**, **Tm**, **Player**, **Pos**, **Age**, and **Year** like we have in our *master_df* variable.

We will process the *test_df* dataframe in the same way.

```{r process_test}

# filter out certain rounds
test_df <- test_df %>%
  filter(Rnd < 8)
  
# get rid of blank rows
test_df <-test_df[!(test_df$Player=="Player"),]
  
# filter so dataframe only contains offensive skill position players.
test_df <- test_df %>%
  filter(Pos == "QB" | Pos == "WR" | Pos == "RB")

test_df[is.na(test_df)] <- 22

test_df$Pick <- as.integer(test_df$Pick)
test_df$Age <- as.integer(test_df$Age)
test_df$Tm <- as.factor(test_df$Tm)
test_df$Pos <- as.factor(test_df$Pos)

kable(head(test_df))
```

Now let's create a dataframe in which we can compare different positions that were drafted. First, we want to break up our data into 4 periods. Then for each period, we will take average career value of each position grouped by each round that the player was selected. We will make a new *pos_df* dataframe with these groupings.

```{r positions}
pos_df <- master_df %>%
  mutate(period = cut(year, breaks=4)) %>%
  group_by(period, Pos, Rnd) %>%
  summarise(Avg_AV = mean(CarAV))

kable(head(pos_df))
```

Let's also add a dataframe *off_df* that is the same as *master_df*, but contains a variable **roty** that is Yes when the player that was drafted from 1970-2016 was Offensive Rookie of the Year, and No otherwise. We will also filter the dataframe to only contain offensive skill position players, like we did for the 2020 draft data.

```{r off_roty}
off_df <- master_df %>%
  mutate(roty = ifelse(Player %in% roty_df$Player, "Yes", "No")) %>%
  filter(Pos == "QB" | Pos == "WR" | Pos == "RB")

off_df$roty <- as.factor(off_df$roty)

kable(head(off_df))
```

# Part 3: Exploratory Data Analysis

## Trends in Average Value

Has average value for players selected in different rounds gone up over time?
Have GMs gotten better at drafting in the first round, second round, etc...?

```{r avg_val_rd1}

avg_val_df <- master_df %>%
  group_by(year, Rnd) %>%
  summarise(Avg_AV = mean(CarAV))

avg_val_df %>%
  group_by(Rnd) %>%
  ggplot(mapping=aes(x=year, y=Avg_AV, color=Rnd)) +
    geom_point() +
    labs(x = "Year", y = "Average Career Value", title = "Average Value for Players Drafted in Different Rounds Over Time") + 
    geom_smooth(method=lm) 
```

Seems like GMs have not gotten better at drafting in any of the first four rounds. In fact, we see a slight decline in average value for all rounds over time. We do see that GMs are selecting better players in the earlier rounds, as generally the average value for the earlier rounds is consistently higher than the lower rounds throughout the years. We see the trends spread out as time goes on as well.

## Analyzing the Quarterback Position

Lets analyze the average values of different positions grouped by round and time period in which they were drafted. Let's start with the most important position in football.

```{r qb}
qb_bar <- pos_df %>%
  filter(Pos == "QB") %>%
  group_by(Rnd) %>%
  ggplot(mapping=aes(x=period, y=Avg_AV, fill=Rnd)) +
    geom_bar(stat="identity", position = "dodge") +
    labs(x = "Year", y = "Average Career Value", title = "Average Value for QBs Drafted in Different Rounds Over Different Time Periods")

qb_bar
```

In the past 20 years (2000-2020), it is much more likely to hit on a QB in the first round than in any of the other rounds. We see a huge drop in average value after the first round in the past 20 years. Average value dips in half after that, and continues to decrease until the 7th round. It is interesting to note that the 7th round averge value shoots up again to about the same average values of the 3rd and 4th round in the 2000s.

Before then, from 1990-2000, we see that the 6th round was a  value pick for QB, although Tom Brady might be the outlier that is skewing those numbers. But we also see that there was far more value in the second round QB selection from 1980-2000 than in the past 20 years.

Now let's focus our attention on the past 20 years and graph some visualizations of that data.
```{r qb2}

qb_av_pick <- master_df %>%
  filter(year >= 2000) %>%
  filter(Pos == "QB") %>%
  ggplot(mapping=aes(x=Pick, y=CarAV)) +
    geom_point()  +
    labs(x = "Pick", y = "Career Value", title = "Average Value over picks for QBs Drafted in the 2000s") + 
    geom_smooth(method='loess')

qb_av_pick
```

As we would expect the trend is that there is a decline in value until about pick 100, where the career value seems to be about the same from about pick 100-250. This would suggest that seelcting a QB at picks 100-150 would, statistically speaking, provide less bang for your buck, as you could likely get a player of the same quality with some of your later draft capital.

```{r qb3}

qb_violin <- master_df %>%
  filter(year >= 2000) %>%
  filter(Pos == "QB") %>%
  ggplot(mapping=aes(x=factor(Rnd), y=CarAV)) +
    geom_violin()  +
    labs(x = "Rnd", y = "Career Value", title = "Average Value over Round for QBs Drafted in the 2000s") + 
    geom_smooth(method=lm)

qb_violin
```

As we would expect, the violin plots show us that most of the QBs selected in rounds 5-7 turn out to be busts, as most of the career values end up towards the bottom of the violin. 

However, the distributions reaffirm what we have seen before in our Round 1 QBs. The spread of the data is far greater in round 1, and decreases heavily in round 2, and from there the decreases in spread are less drastic, suggesting that you have more of a shot at getting a good player in round 1 than in any other round.

## Analyzing the WR and RB

Next we will provide the same graphs to provide similar insight into the RB and WR selections of the draft.

It is interesting to note that the general trend has been to select RBs later in the draft, as RBs have always been considered as more expendable than a QB, and there seems to be a notion that you can always get a quality back in the later rounds, and that using first round capital on a RB is a poor management decision.


```{r rb_wr1}

rb_bar <- pos_df %>%
  filter(Pos == "RB" & period == "(2e+03,2.02e+03]") %>%
  group_by(Rnd) %>%
  ggplot(mapping=aes(x=period, y=Avg_AV, fill=Rnd)) +
    geom_bar(stat="identity", position = "dodge") +
    labs(x = "Year", y = "Average Career Value", title = "Average Value for RBs")

wr_bar <- pos_df %>%
  filter(Pos == "WR" & period == "(2e+03,2.02e+03]") %>%
  group_by(Rnd) %>%
  ggplot(mapping=aes(x=period, y=Avg_AV, fill=Rnd)) +
    geom_bar(stat="identity", position = "dodge") +
    labs(x = "Year", y = "Average Career Value", title = "Average Value for WRs")

qb_bar <- pos_df %>%
  filter(Pos == "QB" & period == "(2e+03,2.02e+03]") %>%
  group_by(Rnd) %>%
  ggplot(mapping=aes(x=period, y=Avg_AV, fill=Rnd)) +
    geom_bar(stat="identity", position = "dodge") +
    labs(x = "Year", y = "Average Career Value", title = "Average Value for QBs")

grid.arrange(qb_bar, rb_bar, wr_bar, ncol=3, top = "Average Value in Different Rounds over the 2000s")
```

Not as drastic of a difference in rounds 1 and 2 in the WR group. The RB average value in the 2000s seems to resemble the QB position.

```{r rb_wr2}

qb_av_pick <- master_df %>%
  filter(year >= 2000) %>%
  filter(Pos == "QB") %>%
  ggplot(mapping=aes(x=Pick, y=CarAV)) +
    geom_point()  +
    labs(x = "Pick", y = "Career Value", title = "QB Average Value") + 
    geom_smooth(method='loess')

rb_av_pick <- master_df %>%
  filter(year >= 2000 & Pos == "RB") %>%
  ggplot(mapping=aes(x=Pick, y=CarAV)) +
    geom_point()  +
    labs(x = "Pick", y = "Career Value", title = "RB Average Value") + 
    geom_smooth(method='loess')

wr_av_pick <- master_df %>%
  filter(year >= 2000 & Pos == "WR") %>%
  ggplot(mapping=aes(x=Pick, y=CarAV)) +
    geom_point()  +
    labs(x = "Pick", y = "Career Value", title = "WR Average Value") + 
    geom_smooth(method='loess')

grid.arrange(qb_av_pick, rb_av_pick, wr_av_pick, ncol=3, top = "Average Value Over Picks in the 2000s")

```

Much less steep of a drop off between round 1 to 2 in the WR group.

Again we see a trend that by pick 100 the value seems to hit a plateue.

```{r rb_wr3}

rb_violin <- master_df %>%
  filter(year >= 2000) %>%
  filter(Pos == "RB") %>%
  ggplot(mapping=aes(x=factor(Rnd), y=CarAV)) +
    geom_violin()  +
    labs(x = "Rnd", y = "Career Value", title = "Average Value over Round for RBs") + 
    geom_smooth(method=lm)

wr_violin <- master_df %>%
  filter(year >= 2000) %>%
  filter(Pos == "WR") %>%
  ggplot(mapping=aes(x=factor(Rnd), y=CarAV)) +
    geom_violin()  +
    labs(x = "Rnd", y = "Career Value", title = "Average Value over Round for WRs") + 
    geom_smooth(method=lm)

grid.arrange(qb_violin, rb_violin, wr_violin, ncol=3, top = "Average Value over Round")
```

RBs in Round 1 always produce.
We again see that round 2 is a value round for WRs as it appears to resemble the type of value you get out of round 1.

# Part 4: Machine Learning

## Predicting the Rookie Offensive MVP

Now, right off the bat, we hope that the model will predict that Joe Burrow has a higher likelihood of winning the MVP. Not only because he's a stud, but because he's fresh off the Heisman, and the first overall pick QB that is going to a team in desperate need of good QB play. Vegas has him as the clear favorite to win, and the season is set up for him to take the title, so if our model is worth anything, it should at the very least have Joe Burrow as one of its top predictions for the award.

First, lets control the resampling of our data. In this case, weâ€™re going to cross-validate the data 3 times, therefore training the model 3 times on different portions of the data before settling on the best tuning parameters. For gbm, the tuning parameters are trees, shrinkage, and interaction depth.

```{r ml_control}

objControl <- trainControl(method='cv', number=3, returnResamp='none', summaryFunction = twoClassSummary, classProbs = TRUE)

```

# Creating our Model

Now to actually train the model...

First, we will set the predictor variables to **Tm**, **Pos**, and **Pick**, and the sole outcome variable as **roty**. Then we will use the *train()* method from the caret package to train the model using the *off_df* variable that contains all our historical draft data on all the offensive skill position players.

```{r train_model}

outcome_name <- 'roty'
predictor_names <- c('Tm', 'Pos', 'Pick')

set.seed(123)
model <- train(off_df[,predictor_names], off_df[,outcome_name], 
               method = "gbm",
               trControl = objControl,
               metric = "ROC",
               preProc = c("center", "scale"))
```

We will print the summary of the model below, which will display the relative influences of each of the predictor variables.

```{r sum_model}
summary(model)
```

The summaries tell us how much relative influence each variable had on the model. It was interesting to see that position had such absolutely zero influence in predicting the model. This tells us that quarterbacks, wide receivers, or running backs do not have a leg up on each other for the MVP award! 

What is even more interesting is that the team the player was drafted to seemed to influence the model more than the pick number itself! Before I had trained the model, I expected pick, position, and then team to have relative influence in that order.


# Testing against 2017-2019 data

Let's test our model against the 2017, 2018, and 2019 datasets. To do this, we will use the *predict()* function in the caret package and feed it the test data. From there,  *predict()* will calculate probabilities that the model is sure about it choice that each observation from *test_df* will fall under the "Yes" and "No" outcome categories. So the "Yes" variable corresponds to the probability the model is sure about its choice that the player will become Rookie MVP, and "No" = probability the model is sure the player will not be the Rookie MVP.

```{r eval_test}

predictions <- predict(object=model, test_df[,predictor_names], type='prob')
kable(head(predictions))
```

Now let's join our prediction probabilities to the actual data, so we can look at the prediction probabilities for each player.

```{r join_probabilities_test}

test_df <- merge(test_df, predictions, by = "row.names", all.x = FALSE, all.y = FALSE)
test_df$No.x <- NULL

kable(head(test_df))
```

Now let's get the top 10 players that the model is most certain will be the Offensive Rookie of the Year for 2017, 2018, and 2019.

```{r top10_roty_test}

top10_roty_2017 <- test_df %>%
  filter(year == 2017) %>%
  top_n(10, Yes)

kable(top10_roty_2017)

top10_roty_2018 <- test_df %>%
  filter(year == 2018) %>%
  top_n(10, Yes)

kable(top10_roty_2018)

top10_roty_2019 <- test_df %>%
  filter(year == 2019) %>%
  top_n(10, Yes)

kable(top10_roty_2019)
```


The actual winners for Rookie Offensive MVP for 2017-2019 were Alvin Kamara, Saquon Barkley, and Kyler Murray (in that order). The model fails to list Kamara as a top 10 prediction for 2017, but lists Barkley as its fourth best prediction for 2018, and Murray as its top prediction for 2019!

# Predicting the 2020 Rookie Offensive MVP

Now let's use the model to predict the probabilities that each player from the 2020 draft will become Offensive Rookie of the Year.  Like we did for the testing portion, this code will give us the probability that the model is sure about its choice that the observation will fall under the "No" and "Yes" category.

```{r eval_2020}

predictions <- predict(object=model, df_2020[,predictor_names], type='prob')
```

Now let's join our prediction probabilities to the actual data like we did before. s

```{r join_probabilities}

df_2020 <- merge(df_2020, predictions, by = "row.names", all.x = FALSE, all.y = FALSE)
df_2020$No.x <- NULL

kable(head(df_2020))
```

Now let's get the top 10 players that the model is most certain will be the Offensive Rookie of the Year

```{r top10_roty}

top10_roty <- df_2020 %>%
  top_n(10, Yes)

kable(top10_roty)
```

Joe Burrow is our model's top prediction to win the MVP!!! We also see that Cam Akers, Tua, Henry Ruggs III, Jerry Jeudy, CeDee Lamb, and Justin Jefferson also appear in the top 10. All of these players are among those that have the highest odds to win the the Offensive MVP according to OddsShark.

Again, it's important to highlight that we trained this model JUST based on the pick number, team, and position for each player, whereas the Vegas odds have most certainly taken into account the player's performance in college as well.